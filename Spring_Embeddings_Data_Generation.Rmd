---
title: "Untitled"
author: "Jonathan Bourne"
date: "22/10/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
packages <- c("rlang", "tidyverse", "igraph", "devtools", "minpack.lm", "foreach", "doParallel" )

new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

sapply(packages, library, character.only = TRUE)



#install_github("JonnoB/PowerGridNetworking")
library(PowerGridNetworking)

#Set up file system to read the correct folders this switches between aws and windows mode

#creates the correct root depending on whether this is on the cloud or not
if(dir.exists("/home/jonno")){
  #This folder is for use on my machine
  project_folder <- "/home/jonno/Dropbox/IEEE_Networks"
  basewd <- "/home/jonno"
}else{
  #This is for the folder that is on the cloud
  project_folder <- "~/Dropbox/IEEE_Networks"
  basewd <- "~/Dropbox"
}

power_grid_graphs_path <- file.path(project_folder, "power_grid_graphs") #The path where the base igraph representations of the power grids are
collapse_sets <- file.path(project_folder, "collapse_sets") #the full collapse set of each power grid and the permutations are stored here
collapse_set_summaries <- file.path(project_folder, "collapse_set_summaries")
permuted_IEEE_118_path <- file.path(power_grid_graphs_path, "Permuted_IEEE_118") #The permuted base IEEE-118 igraphs are stored here
edge_scramble_keys_path <- file.path(project_folder, "edge_scramble_keys")
edge_scramble_keys_IEEE_permutation_path <- file.path(edge_scramble_keys_path, "Permuted_IEEE_118")
#The path where the permuted and attacked graph lists of the IEEE graphs are stored
#summary_path <- 

c(power_grid_graphs_path, collapse_sets, collapse_set_summaries, permuted_IEEE_118_path, edge_scramble_keys_path, edge_scramble_keys_IEEE_permutation_path) %>% walk(~{
  if(!file.exists(.x)) dir.create(.x, recursive = T)
})

#Load some other useful functions
list.files(file.path(basewd, "Useful_PhD__R_Functions"), pattern = ".R", full.names = T) %>%
  walk(~source(.x))

list.files(file.path(basewd, "Flow_Spring_System"), pattern = ".R", full.names = T) %>%
  walk(~source(.x))


##
##
## These are the ec values that will be used and also the fraction of total scrambles that will be used in the analysis
##
##

#The alpha/ec values to scramble
Scramble_ec_values <- c(1.005, 1.025, 1.05, 1.1, 1.2, 1.5, 2, 3, 5, 7, 10, 20) 

#The fraction of edges that will be scrmabled for each scrambled alpha
fract_vect <- c(1, 0.75, 0.5, 0.25) #0.75 can also be added but may overlap with the others too much


```



##Create permuted IEEE-118 networks
```{r}
#Create a list of IEEE-118 networks where the demand and gen node values are internally permuted
set.seed(1235)
random_seeds <- sample(1:10000, 30)

g <- readRDS(file.path(power_grid_graphs_path, "IEEE_118_igraph.rds")) 

 
Permuted_IEEE_118_list <- random_seeds %>% map(~{
  g <- permute_gen_dem(g, .x)
  
  g <-  BalencedGenDem(g, 
                        Demand = "demand",
                        Generation = "generation",
                        OutputVar = "net_generation")
  
  SlackRef <- SlackRefFunc(g, name = "name", Generation = "generation")
  
  g <- PowerFlow(g, SlackRef$name, EdgeName ="edge_name", VertexName = "name", Net_generation = "net_generation", power_flow = "power_flow")

})

#Save the networks so that they can be used by the HPC 

1:length(Permuted_IEEE_118_list) %>%
  walk(~{
    saveRDS(Permuted_IEEE_118_list[[.x]], 
            file.path(permuted_IEEE_118_path, 
                      paste0("Permutation_", .x, ".rds")))
  })

#clean up the workspace. The graphs can just be loaded when needed
rm(g); rm(Permuted_IEEE_118_list)


```


#Create edge scrambles

Create the edge scrambles that give a range of alpha values for each initial ec/alpha value

returns a data frame that contains (amongst other things), a random seed and the associated alpha value is the network edges are scrambled using that random seed.

*N.B*
This chunk requires a large number of networks to be loaded and analysed so takes a long time. doing this in parallel is reccomended. However, I haven't been able to make it work effectively so keep it in parallel.

```{r}
networks_in_project <- list.files(power_grid_graphs_path, recursive = T)

for(n in 1:length(networks_in_project)){
          
          #load the graph for the edge scrambles to be calculated
          g <- readRDS(file.path(power_grid_graphs_path, networks_in_project[n]))
          
          
          #only creat the target orders if necessary
          if(file.exists(file.path(edge_scramble_keys_path, networks_in_project[n]))){
            
            print("file exists continuing to next network permutation")
          } else{
            
            
            target_orders_temp <- create_target_orders_for_strain_test(g, fract_vect, Scramble_ec_values,
                                                                       total_sample_space = 10000, #Larger number mean bigger extremes but it takes much longer. I choose 10k as a painful slow medium
                                                                       required_samples_out = 10,
                                                                       seed = n ) #previously a constant 123
            
            saveRDS(target_orders_temp, file.path(edge_scramble_keys_path, networks_in_project[n]))
          }
          
        }
```

#Create parameter dataframe


I need to make this work for all the graphs not just the permutations. I can filter out the non-IEEE after words

The parameter dataframe allows for efficient parallel processing of the large number of simulations performed in this project.

The parameter dataframe can be saved and used later on a different system such as an HPC or cloud machine.

```{r}


#The target orders need to be combined into a single dataframe so that each job in the array has it's parameters defined
parameter_df <-  list.files(edge_scramble_keys_IEEE_permutation_path, full.names = T) %>% 
  map_df(~{
  target_order <-.x
  #expand grid creates a two column tibble which is not what I want, so I have to do this two stage process
  temp <- readRDS(target_order) %>% as.data.frame() %>%
    expand_grid(df = ., simulation_id = 1:100) 
  
  temp2 <- temp$df %>% mutate(simulation_id = temp$simulation_id, 
                              permutation = gsub("[^0-9]","",basename(target_order)) %>% as.integer() )
  return(temp2)
})


parameter_df <- parameter_df %>% mutate(deletion_seed = 1:n(), #set the random deletion seed to be the job number. This guarentees a different order for every simulation
                                        scramble_network = ifelse(is.na(fract), FALSE, TRUE)) %>%
  left_join(tibble(graph_path = list.files(permuted_IEEE_118_path, full.names = T), 
                   permutation = gsub("[^0-9]","",basename(graph_path)) %>% as.integer()), by = "permutation" 
  ) %>%
  mutate(
    sub_path = file.path( #The collapse set and the collapse set summary paths are identiacal apart from the root.
      paste0("Permutation_", permutation), 
      paste0("fract_", fract, "_ec_", ec, "_v_", v), 
      paste0("simulation_id_", simulation_id, ".rds" )),
    collapse_path = file.path(collapse_sets,sub_path),
    collapse_summary_path = file.path(collapse_set_summaries, sub_path))%>%
  ungroup %>%
  group_by(ec) %>% #break the parameter table into sets of twelve where each set contains every ec level. This allows for a longer and more stable clock time
  mutate(compute_group = 1:n()) %>%
  ungroup

saveRDS(parameter_df, file.path(project_folder, "IEEE_118_permutatio_parameter_file.rds"))
```

#Base esge scramble codes

```{r}
#The target orders need to be combined into a single dataframe so that each job in the array has it's parameters defined
parameter_df <-  list.files(edge_scramble_keys_path, full.names = T, pattern = ".rds") %>% 
  map_df(~{
  target_order <-.x
  #expand grid creates a two column tibble which is not what I want, so I have to do this two stage process
  temp <- readRDS(target_order) %>% as.data.frame() %>%
    expand_grid(df = ., simulation_id = 1:100) 
  
  temp2 <- temp$df %>% mutate(simulation_id = temp$simulation_id, 
                              permutation = basename(.x) %>% gsub(".rds", "",.))
  return(temp2)
})


parameter_df <- parameter_df %>% mutate(deletion_seed = 1:n(), #set the random deletion seed to be the job number. This guarentees a different order for every simulation
                                        scramble_network = ifelse(is.na(fract), FALSE, TRUE)) %>%
  left_join(tibble(graph_path = list.files(power_grid_graphs_path, full.names = T, pattern = ".rds"), 
                   permutation = basename(graph_path) %>% gsub(".rds", "",.)), by = "permutation" 
  ) %>%
  mutate(
    sub_path = file.path( #The collapse set and the collapse set summary paths are identiacal apart from the root.
      paste0("Permutation_", permutation), 
      paste0("fract_", fract, "_ec_", ec, "_v_", v), 
      paste0("simulation_id_", simulation_id, ".rds" )),
    collapse_path = file.path(collapse_sets,sub_path),
    collapse_summary_path = file.path(collapse_set_summaries, sub_path))%>%
  ungroup %>%
  group_by(ec) %>% #break the parameter table into sets of twelve where each set contains every ec level. This allows for a longer and more stable clock time
  mutate(compute_group = 1:n()) %>%
  ungroup

saveRDS(parameter_df, file.path(project_folder, "base_parameter_file.rds"))
```


#Load the collapse set summaries
```{r}

Permuted_IEEE_118_results <- list.files(path = collapse_set_summaries, 
                                        # pattern = ".rds", I saved them wrong, the code has been corrected but not re-run
                                        full.names = TRUE, 
                                        recursive = TRUE) %>%
  map_df(~read_rds(.x)%>%
           mutate(file_path = .x))   %>%
  arrange(-TotalNodes) %>%
  mutate(has_gc = mean_degree_sqrd > 2*mean_degree) %>%
  filter(!has_gc) %>%
  group_by(file_path) %>%
  summarise_all(first)  %>%
  #### This is not necessary after re-calc as all the info is included with the extracted data
  left_join(parameter_df %>% 
              select(file_path  = collapse_summary_path, 
                     ec:permutation), by  = "file_path") %>%
  ###
  group_by(ec, v, fract, permutation) %>%
  summarise(NodesAttacked = mean(NodesAttacked)) 


##After this the strain needs to be added

#Why is the grid loading so high for the alpha == 20 grids?
test <- Permuted_IEEE_118_results %>% filter(NodesAttacked==0) %>%
  mutate(alpha = 1/GridLoading)

parameter_df %>%
  filter(v == 1, fract == 1, permutation == 1, simulation_id==1) %>%
  pull(alpha)


g <- readRDS(file.path("/home/jonno/Dropbox/IEEE_Networks/power_grid_graphs/Permuted_IEEE_118/", "Permutation_1.rds")) %>%
  Proportional_Load(., alpha = 20)

edge_order_df <- Create_scrambled_edges(g, 2798, fract = 1) %>%
  mutate(loading = 1/alpha)

test <- edge_order_df %>%
  summarise(mean_alpha = mean(alpha),
            median_alpha = median(alpha),
            mean_loading = mean(loading),
            median_loading = median(loading))

```

