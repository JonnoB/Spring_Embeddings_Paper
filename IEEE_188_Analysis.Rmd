---
title: "Untitled"
author: "Jonathan Bourne"
date: "29 April 2019"
output: html_document
editor_options: 
  chunk_output_type: console
---
R spatial analysis
https://www.r-spatial.org/r/2019/09/26/spatial-networks.html

foremost -i /dev/sda3 -t R -o /root/restored/

This script is for performing the spring analysis on IEEE_118. The output of this script is used in the Spring Embeddings project. It was kept as a separate script as the outputs my be used more generally in the PhD.

The script requires that the IEEE_118 network has been generated already


This will chunk need to be copy and pasted into the console or the whole RMD file pasted into a new RMD file in AWS.
```{r}
# library("RStudioAMI")
# 
# #Follow instructions to link to dropbox
# linkDropbox()
# 
# #excluding from syncing will probably have to be done a few times, if you have many things in your drop box
# excludeSyncDropbox("*")
# 
# 
# #Once everything is excluded get the key dropbox folders for these simulations
# includeSyncDropbox("IEEE_Networks")
# includeSyncDropbox("Flow_Spring_System")
# includeSyncDropbox("Useful_PhD__R_Functions")
```

#Set up

```{r}

packages <- c("rlang", "tidyverse", "igraph", "devtools", "minpack.lm", "foreach", "doParallel" )

new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

sapply(packages, library, character.only = TRUE)



install_github("JonnoB/PowerGridNetworking")
library(PowerGridNetworking)

#Set up file system to read the correct folders this switches between aws and windows mode

#creates the correct root depending on whether this is on the cloud or not
if(dir.exists("/home/jonno")){
  #This folder is for use on my machine
  Project_folder <- "/home/jonno/Dropbox/IEEE_Networks"
  basewd <- "/home/jonno"
}else{
  #This is for the folder that is on the cloud
  Project_folder <- "~/Dropbox/IEEE_Networks"
  basewd <- "~/Dropbox"
}

IEEE_networks <- file.path(Project_folder, "IEEE_network_files")

#Load some other useful functions
list.files(file.path(basewd, "Useful_PhD__R_Functions"), pattern = ".R", full.names = T) %>%
  walk(~source(.x))

list.files(file.path(basewd, "Flow_Spring_System"), pattern = ".R", full.names = T) %>%
  walk(~source(.x))

#Load the IEEE-118 network
#This network is created by the markdown script Create_IEEE_NEtworks.Rmd also in this repository
IEEE_118 <- readRDS(file = file.path(IEEE_networks, "IEEE_118_igraph.rds"))
```



#PL attack IEEE118
##Edges
```{r}

# 
# setwd(file.path(Project_folder, "IEEE118_edges"))
# 
# #rep <-5 #I don't think this does anything. If nothing breaks then delete.
# alpha_vector <- c(1, 1.02, 1.01, 1.005, 1.05, 1.1, 1.2, 1.5, 2, 3, 5, 7, 10, 15, 20, 30, 50, 100, 200, Inf)
# alpha_vector
# set.seed(21256)
# DeleteOrders_Edges <- MultiAttackOrder(IEEE_118, Target ="Edges", Sims = 100, Name = "Link")
# 
# #Create the simulations for each of the alpha avalues using 100 simulations for each
# alpha_vector %>% walk(~{
#   gProp <- Proportional_Load(IEEE_118, alpha = .x)
# 
#   folder <- paste0("alpha_value_",  .x*100)
#   #create folder if it doesn't already exist
#   if(!file.exists(folder)){
#     dir.create(folder)
#   }
# 
#   CascadeMode <- ifelse(is.finite(.x), TRUE, FALSE)
# 
#   SaveMultiAttacks(gProp, DeleteOrders_Edges, folder,
#                    TotalAttackRounds = 1000,
#                    CascadeMode = CascadeMode,
#                    Demand = "Load_MW",
#                    Generation = "Generation_MW",
#                    EdgeName = "Link",
#                    VertexName = "name",
#                    Net_generation = "Net_Generation",
#                    Target = "Edges")
# 
# }
# 
# )
# 


```

##Nodes
I am not doing nodes for this experiment. Previous results (now deleted) suggest that node analysis is not hugely different anyway

#Target orders

Create the target orders for the scrambled edge values
##ec values to attack
```{r}
#The alpha/ec values to scramble
Scramble_ec_values <- c(1.005, 1.01, 1.05, 1.1, 1.2, 1.5, 2, 3, 5, 7, 10, 20) 

#The fraction of edges that will be scrmabled for each scrambled alpha
fract_vect <- c(1, 0.75, 0.5, 0.25) #0.75 can also be added but may overlap with the others too much

```


Generate the target orders that will be used to ensure that the random edge permutations are consistant across the analysis.

This can take a while for large numbers (e.g 10k samples), as each graph needs to be generated and the new alpha value found.
```{r}
# 
# target_orders <- fract_vect %>% map_df(~{
# 
#   file_name <- paste0("target_orders_fract_", .x*100, ".rds")
# 
#   current_fract <- .x
# 
#   if(!file.exists(file.path(Project_folder, "target_orders", file_name))){
# 
#   set.seed(123)
#   random_seeds <- sample(1:100000, 10000)
# 
#   target_orders <- Scramble_ec_values %>% map_df(~{
# 
#     print(.x)
#     #create network
#     Scrambled_edge_cap <-  Proportional_Load(IEEE_118, alpha = .x)
#     #permute edges
#     print("creating the random permutations")
#     seed_alpha <- Permute_excess_capacity(Scrambled_edge_cap, random_seeds, fract = current_fract)
#     #take subselection
#     target_orders <- sub_selection_of_seed_alpha(seed_alpha, total_samples = 10, seed = 123) %>%
#       mutate(ec = .x,
#              v = 1:n(),
#              scramble_fract = current_fract)
# 
#     return(target_orders)
# 
#   })
# 
#   saveRDS(target_orders, file.path(Project_folder, "target_orders", file_name))
# 
# } else {
# 
#   target_orders  <- readRDS(file.path(Project_folder, "target_orders", file_name))
# 
# }
#  return(target_orders)
# 
# })

```

#Fixed EC multi-attack

Two loops

* select fraction
* select scramble value
* attack

The attack goes through all the fractions of scramble as well as all the combinations of random scramble.
It may take a couple of days to calculate. Best done on the cloud if possible

##Edge attack
```{r}
# IEEE_118 <- readRDS(file = file.path(IEEE_networks, "IEEE_118_igraph.rds"))
# 
# 
# #These two lines of code are in the PL attack section. the seed ensures the attack order is the same, although it probably doesn't have a very large effect
# set.seed(21256)
# DeleteOrders_Edges <- MultiAttackOrder(IEEE_118, Target ="Edges", Sims = 100, Name = "Link")
# 
# #fract_vect %>%
# fract_vect[1] %>%   #used for splitting up the attacks across the fractions
#   walk(~{
# 
#   current_fract <- .x
# 
# Scramble_ec_values %>%
#   walk(~{
# 
#     target_orders_x <- target_orders %>%
#       filter(ec == .x, scramble_fract == current_fract)
# 
#     folder <- paste0("alpha_value_",  .x*100) %>%
#       file.path(Project_folder, paste0("IEEE_permute_edge_ec_Edge_fract_", current_fract), .)
# 
#     #create folder if it doesn't already exist
#     if(!file.exists(folder)){
#       dir.create(folder, recursive = TRUE) #create all folders in the path if necessary
#     }
# 
#     #
#     #attack network using the deletion orders
#     #
# 
#     setwd(folder)
#     #create network
#     Scrambled_edge_cap <-  Proportional_Load(IEEE_118, alpha = .x)
#     #attack!
#     Scrambled_Edge_SaveMultiAttacks(target_orders_x, Scrambled_edge_cap,
#                                     "constant_ec_v", DeleteOrders_Edges, Target = "Edges", fract = current_fract)
# 
#   })
# 
# })
```


#Calculate strain of the selected networks


##Common values
The below chunk was put in due to simulations being run with different parameters resulting in out of synch heights. The common values will be used for both the proportionally loaded edges and the ec scrambled edges
```{r}
common_time <- 0.01
common_Iter <- 20000
common_tol <- 1e-10
common_mass <- 1


Standardisesd_solution_finder <- function(g, common_time, common_Iter, common_tol, common_mass){
  #This function is just a wrapper to tidy up the code chucnks in finding various strain heights for IEEE_118

   current_graph  <- g %>%
    set.edge.attribute(. , "distance", value = 1) %>%
    Calc_Spring_Youngs_Modulus(., "PowerFlow", "Link.Limit", minimum_value = 100, stretch_range = 1000) %>%
    set.edge.attribute(., "Area", value = 1) %>%
  Normalize_load(., EdgeName = Link, VertexName = name, Net_Generation = Net_Generation, capacity = Link.Limit)


  List_of_BiConComps <- Create_balanced_blocks(current_graph, force = "Net_Generation")

    giant_componant <-List_of_BiConComps %>% map_dbl(~vcount(.x)) %>% which.max()

  #use the largest block to set the simulation parameters k and m.
  #k needs to be sufficiently stretch to allow enough topology variation. otherwise all that happens is a surface angled in the direct of net power flow. Which is interesting but not that interesting
      OriginBlock_complete <- Find_network_balance(g = List_of_BiConComps[[giant_componant]],
                                                   force ="Net_Generation",
                                                   flow = "PowerFlow",
                                                   distance = "distance",
                                                   capacity = "Link.Limit",
                                                   tstep = common_time,
                                                   tol = common_tol,
                                                   maxIter = common_Iter,
                                                   mass = common_mass,
                                                   verbose = FALSE)

      final_z <- Create_stabilised_blocks(g = current_graph,
                                          OriginBlock = OriginBlock_complete,
                                          OriginBlock_number = giant_componant,
                                          force ="Net_Generation",
                                          flow = "PowerFlow",
                                          distance = "distance",
                                          capacity = "Link.Limit",
                                          tstep = common_time,
                                          tol = common_tol,
                                          maxIter = common_Iter,
                                          mass = common_mass,
                                          verbose = FALSE)


}

```


##Proportionally loaded spring system

calcualtes the embeddings of the proportionally loaded systems indicated in the alpha vector

```{r}

# IEEE_118 <- readRDS(file.path(Project_folder,"IEEE_network_files", "IEEE_118_igraph.rds"))
# 
# 
# #Network loadings to find the angles for
# alpha_vector <- c(1, 1.02, 1.01, 1.005, 1.05, 1.1, 1.2, 1.5, 2, 2.5, 3, 5, 7, 10, 15, 20, 50, 100, 200, Inf)
# 
# if(!file.exists(file.path(Project_folder, "Solved_height_networks_PL"))){
#   dir.create(file.path(Project_folder, "Solved_height_networks_PL"))
# }
# 
# 
# #calculate theta for all values of alpha
# alpha_vector %>% walk(~{
# 
#   alpha <- .x
#   file_path <- file.path(Project_folder,"Solved_height_networks_PL", paste0("IEEE_118_alpha_", alpha, ".rds"))
#   
#   if(file.exists(file_path)){
#     
#     print("file exists continueing to next file")
#     
#   }else {
#     
#       print(paste("alpha value", alpha))
# 
#   current_graph <- IEEE_118 %>% Proportional_Load(., alpha = alpha)
# 
#   final_z <- Standardisesd_solution_finder(current_graph, common_time, common_Iter, common_tol, common_mass)
# 
#   write_rds(final_z, file_path)
#     
#   }
# 
# })
# 


```


##Scrambled edge embeddings

Calculates the embeddings of the scrambled edge systems across all the fractions

This code is designed to be spread across several machines. It doesn't seem to paralellise well, I am doing something wrong but haven't worked out how to fix it, hence the multiple-machines solution.

An alternative is to assign 1 fraction per machine. Do whatever you want.

```{r}
# 
# cpu_id <- 1
# number_of_cpus <- 4
# 
# target_orders2 <- target_orders %>%
#   mutate(file_path = file.path(Project_folder,
#                                paste0("constant_ec_from_alpha_fract_", scramble_fract),
#                                paste0("Solved_height_networks_alpha_", ec*100),
#                                paste0("IEEE_118_alpha_", v, ".rds")),
#          calc_on_this_machine = rep_along(file_path, 1:number_of_cpus)) %>%
#   filter(calc_on_this_machine == cpu_id,
#          ec <= 20)
# 
# 1:nrow(target_orders2) %>%
#   walk(~{
# 
#     target <- target_orders2 %>%
#       slice(.x)
# 
#     #does the file exist?
#     if(file.exists(target$file_path)){
#       print("file exists continueing to next file")
#     }else {
# 
#       #if the file doesn't exist ensure that the folder is created and then calculate
#       if(!dir.exists(dirname(target$file_path))){
#         dir.create(dirname(target$file_path), recursive = TRUE)
#       }
# 
#       print(paste0("fraction ", target$scramble_fract ," ec value ", target$ec, ". v ",target$v))
#       #create network
#       Scrambled_edge_cap <-  Proportional_Load(IEEE_118, alpha = target$ec)
# 
#       #create dataframe of new edge limits
#       temp <-Create_scrambled_edges(Scrambled_edge_cap, target$seed, fract = target$scramble_fract)
# 
#       print(mean(temp$alpha))
# 
#       final_z <- Standardisesd_solution_finder(Scrambled_edge_cap %>%
#                                                  set.edge.attribute(., "Link.Limit", value = temp$Link.Limit),
#                                                common_time, common_Iter, common_tol, common_mass)
# 
#       write_rds(final_z, target$file_path)
# 
#     } #proceed to next iteration
# 
#   })

```



#Permuted IEEE118

This chunk creates 30 permutates of IEEE where the generation nodes have been permuted and the demand nodes have been permuted.

We then repeat the previous set of scrambles for each permutation

##Create networks
```{r}
#The path the target orders will be stored at
Permuted_IEEE_118_path <- file.path(Project_folder, "target_orders", "Permuted_IEEE_118")

#create the folder if necessary
if(!dir.exists(Permuted_IEEE_118_path)){
  dir.create(Permuted_IEEE_118_path, recursive = TRUE)
}


#Create a list of IEEE-118 networks where the demand and gen node values are internally permuted
set.seed(1235)
random_seeds <- sample(1:10000, 30)

Permuted_IEEE_118_list <- random_seeds %>% map(~{
  g <- Permute_IEEE(IEEE_118, .x)
  
  g8 <-  BalencedGenDem(g, 
                        Demand = "Load_MW",
                        Generation = "Generation_MW",
                        OutputVar = "Net_Generation")
  
  SlackRef <- SlackRefFunc(g, name = "name", Generation = "Generation_MW")
  
  g <- PowerFlow(g, SlackRef$name, EdgeName ="Link", VertexName = "name", Net_generation = "Net_Generation")
})
```


##target orders

Generate the target orders in parallel... becuase ain't nobody got time for that
```{r}

registerDoParallel(cores=4) #RUNS ON ALL CORES!
foreach(n = 1:length(Permuted_IEEE_118_list),
        .packages = c("PowerGridNetworking", "rlang", "dplyr", "igraph", "stringr", "purrr", "tidyr")) %dopar%{

  file_name <- paste0("target_permutation_", n, ".rds")
  #only creat the target orders if necessary
  if(file.exists(file.path(Permuted_IEEE_118_path, file_name))){

    print("file exists continueing to next network permutation")
  } else{

    target_orders_temp <- Create_target_orders_for_strain_test(Permuted_IEEE_118_list[[n]], fract_vect, Scramble_ec_values,
                                                               total_sample_space = 10000, #Larger number mean bigger extremes but it takes much longer. I choose 10k as a painful slow medium
                                                               required_samples_out = 10,
                                                               seed = 123 )

    saveRDS(target_orders_temp, file.path(Permuted_IEEE_118_path, file_name))
  }

}
  stopImplicitCluster()



```


##Attack ec

Here I attack the randomly permuted edges where the EC is fixed. The concept with the below chunk is that each of the machines used to get the attack results works on each permutation of IEEE-118. This means that each attack set is finished before teh next one is started. This allows me to check that everything is working the way it should.

Outer loop: Permutation to be calculated
Inner loop: the particular target order

```{r}

# cpu_id <- 1
# number_of_cpus <- 1
# 
# set.seed(21256)
# DeleteOrders_Edges <- MultiAttackOrder(IEEE_118, Target ="Edges", Sims = 100, Name = "Link")
# 
# 1:30 %>%
#   walk(~{ #Outer loop choose the permutation
# 
#     #Select the current graph permutation to work on
#     current_graph <- Permuted_IEEE_118_list[[.x]]
#     
#     #load the graph scramble seeds for this network permutation.
#     target_orders <- readRDS(file.path(Permuted_IEEE_118_path,  paste0("target_permutation_", .x, ".rds"))) %>%
#       mutate(folder_path = file.path(Project_folder,
#                                      "Permuted_IEEE_118_collapse_set",
#                                      paste0("Permutation_", .x),
#                                      paste0("fract_", fract, "_ec_", ec*100, "_v_", v)))     %>%
#       arrange(-ec) %>%#order the clculations so that the slow ones are first. this makes the paralellisation more efficient
#       #by preventing cpu's finishing whilst slow calculations are in progress. This way the the cpu's will finish each permutation on the smallest fastest ec values, minimising non-active cpu time
#       mutate(calc_on_this_machine = rep_along(folder_path, 1:number_of_cpus),
#              ID  = 1:n()) %>%
#       
#       filter(calc_on_this_machine == cpu_id) #keep only the elements to be calculated on this machine
# 
#     Scrambled_Edge_SaveMultiAttacks_parallel(current_graph, target_orders, DeleteOrders_Edges , Target = "Edges", cores = 5)
#   })

#You can't make a single dataframe to do the multi attack until you can work out how to load different networks according to which permutation is being used

#Creates a dataframe of all the permutations all 30 sets.
#This reduces inactive cpus at the end of each set
#It Also makes the code easier to read
# target_orders_attack <- 1:30 %>%
#   map_df(~{ #Outer loop choose the permutation
# 
#     #Select the current graph permutation to work on
#     current_graph <- Permuted_IEEE_118_list[[.x]]
# 
#     #load the graph scramble seeds for this network permutation.
#     target_orders <- readRDS(file.path(Permuted_IEEE_118_path,  paste0("target_permutation_", .x, ".rds"))) %>%
#       mutate(folder_path = file.path(Project_folder,
#                                      "Permuted_IEEE_118_collapse_set",
#                                      paste0("Permutation_", .x),
#                                      paste0("fract_", fract, "_ec_", ec*100, "_v_", v)),
#              calc_on_this_machine = rep_along(folder_path, 1:number_of_cpus),
#              ID  = 1:n()) %>%
#       filter(calc_on_this_machine == cpu_id) #keep only the elements to be calculated on this machine
#  
#   })
# 
#    Scrambled_Edge_SaveMultiAttacks_parallel(current_graph, target_orders_attack, DeleteOrders_Edges , Target = "Edges", cores = detectCores())

```

##Strain Calc

```{r}


#library(future.apply)
cpu_id <- 1
number_of_cpus <- 1

permuted_strain_folder <- file.path(Project_folder,"Permuted_IEEE_118_strain_set")

if(!file.exists(permuted_strain_folder)){
  dir.create(permuted_strain_folder)
}

#Create the target orders across all permutations
#ensures the file path links to the strain folder not the collapse folder
target_orders_strain <- 1:length(Permuted_IEEE_118_list) %>% map_df(~{
  
  current_graph <- Permuted_IEEE_118_list[[.x]]
  
  file_name <- paste0("target_permutation_", .x, ".rds")
  #only creat the target orders if necessary
  
  target_orders2 <-read_rds(file.path(Permuted_IEEE_118_path, file_name)) %>%
    mutate(file_path = file.path(permuted_strain_folder,
                                 paste0("Permutation_", .x),
                                 paste0("fract_", fract, "_ec_", ec*100, "_v_", v, ".rds")),
           permute = .x,
           calc_on_this_machine = rep_along(file_path, 1:number_of_cpus),
           ID  = 1:n()) %>%
    filter(calc_on_this_machine == cpu_id)
}
)


for(X in 1:nrow(target_orders_strain)){ #use future lapply to parallelize the process
  
  target <- target_orders_strain %>%
    slice(X)
  
  #does the file exist?
  if(file.exists(target$file_path)){
    print(paste0("File ", basename(target$file_path)," for permute ", target$permute, " exists continueing to file: ", X+1, " of ", nrow(target_orders_strain)))
  }else {
    
    #if the file doesn't exist ensure that the folder is created and then calculate
    if(!dir.exists(dirname(target$file_path))){
      dir.create(dirname(target$file_path), recursive = TRUE)
    }
    
    print(paste0("fraction ", target$fract ," ec value ", target$ec, ". v ",target$v))
    #create network
    Scrambled_edge_cap <-  Proportional_Load(Permuted_IEEE_118_list[[target$permute]], alpha = target$ec)
    
    #create dataframe of new edge limits
    temp <- Create_scrambled_edges(g = Scrambled_edge_cap, target$seed, fract = target$fract)
    
    final_z <- Standardisesd_solution_finder(Scrambled_edge_cap %>%
                                               set.edge.attribute(., "Link.Limit", value = temp$Link.Limit),
                                             common_time, common_Iter, common_tol, common_mass)
    
    
    write_rds(final_z, target$file_path)
      print(paste("Convergence", X, "of", nrow(target_orders_strain) ,"complete proceeding to next calculation") )
    
  }
}

```

##parallel version 

doesn't work very well
```{r}

#foreach version
#This doesn't work on my machine but does work on the cloud. I don't know why could be to do with the blas/lapak libraries
registerDoParallel(cores=4)
foreach(X = 1:nrow(target_orders_strain), 
        .packages = c("PowerGridNetworking", "rlang", "dplyr", "igraph", "stringr", "purrr", "tidyr")) %do% { #use future lapply to parallelize the process
          
          target <- target_orders_strain %>%
            slice(X)
          
          #does the file exist?
          if(file.exists(target$file_path)){
            print("file exists continueing to next file")
          }else {
            
            #if the file doesn't exist ensure that the folder is created and then calculate
            if(!dir.exists(dirname(target$file_path))){
              dir.create(dirname(target$file_path), recursive = TRUE)
            }
            
            print(paste0("fraction ", target$fract ," ec value ", target$ec, ". v ",target$v))
            #create network
            Scrambled_edge_cap <-  Proportional_Load(Permuted_IEEE_118_list[[target$permute]], alpha = target$ec)
            
            #create dataframe of new edge limits
            temp <- Create_scrambled_edges(g = Scrambled_edge_cap, target$seed, fract = target$fract)
            
            print(mean(temp$alpha))
            
            final_z <- Standardisesd_solution_finder(Scrambled_edge_cap %>%
                                                       set.edge.attribute(., "Link.Limit", value = temp$Link.Limit),
                                                     common_time, common_Iter, common_tol, common_mass)
            
            
            write_rds(final_z, target$file_path)
            print("Convergence", X, "of", nrow(target_orders_strain) ,"complete proceeding to next calculation", )
            
          }
        }
stopImplicitCluster()

```

##Extract attacks
```{r}

permutation <- 2

Attack_folder <- paste0("/home/jonno/Dropbox/IEEE_Networks/Permuted_IEEE_118_collapse_set/Permutation_", permutation)

Summary_folder <- file.path(Project_folder, "Summary_Permuted_IEEE_118_collapse_set",
                                paste0("Permutation_",  permutation)) ###########change this! to make multiple
    
    #Create the summary folder for that fraction
    if(!file.exists(Summary_folder)){
      dir.create(Summary_folder, recursive = T)
    }
        #extract everything from each of the sub folders of each fraction
ExtractAttackStats_parallel(RootFolder = Attack_folder, 
                            file.path(Summary_folder),
                            Generation = "Net_Generation",
                            EdgeName = "Link",
                            cores = 7)


        ExtractAttackStats(RootFolder = Attack_folder, 
                           file.path(Summary_folder),
                           Generation = "Net_Generation",
                           EdgeName = "Link")


```

##plot results of single permutation

This result shows that permuting the nodes to change the profile still produces more accurate results
```{r}


test <- Create_strain_alpha_results_df(g = Permuted_IEEE_118_list[[2]], 
                                       target_orders = target_orders_strain %>%
                                         filter(permute==2), 
                                       Summary_folder)

current_permutation <- Permuted_IEEE_118_list[[2]] %>%
  set.edge.attribute(., "distance", value = 1)%>%
  set.edge.attribute(., "Link.Limit", value = Inf)

target_orders_temp <- target_orders_strain %>%
  filter(permute == 2) #%>%
  slice(1:428)
  filter(file.exists(target_orders_strain$file_path),permute==1)

#load strain
Permuted_strain_set_df <- 1:nrow(target_orders_temp) %>%
  map_df(~{
    
    load_file <- target_orders_strain %>% slice(.x)
   print(.x)
    Out <- read_rds(load_file$file_path) %>%
    Calc_line_strain(current_permutation, ., distance = "distance", capacity = "Link.Limit", flow = "PowerFlow") %>%
      summarise(strain = mean(strain)) %>%
      bind_cols(load_file, .)
    
    return(Out)
  }) %>%
  select(-file_path)

Permuted_IEEE_118_results <- list.files(path = Summary_folder, 
                                pattern = ".rds", 
                                full.names = TRUE, 
                                recursive = TRUE) %>%
    map_df(~read_rds(.x)%>%
             mutate(file_path = .x))   %>%
    arrange(-TotalNodes) %>%
    mutate(has_gc = mean_degree_sqrd > 2*mean_degree) %>%
    filter(!has_gc) %>%
    group_by(simulationID, file_path) %>%
    summarise_all(first)  %>%
    select(-file_path) %>%
  rename(file_path = alpha) %>%
  mutate(file_path = basename(file_path)) %>%
  left_join(target_orders_strain %>% #add in target orders to get the simulation params
  mutate(file_path = basename(file_path) %>% gsub(".rds", "", .)) %>% filter(permute == 1)) %>% 
  ungroup %>%
  group_by(ec, v, fract, permute) %>%
  summarise(NodesAttacked = mean(NodesAttacked)) %>%
  left_join(target_orders_strain , by = c("ec", "v", "fract", "permute")) %>% ##join the target orders to get the alpha values
  #The second join may be able to be joined in the first step, but it isn't super important.
  select(ec:NodesAttacked) %>%
  left_join(Permuted_strain_set_df,by = c("ec", "v", "fract", "permute")) %>%
  select(-calc_on_this_machine, -ID) %>%
  ungroup %>%
  mutate(alpha = 1/alpha)


#plot

test  %>%
  filter(complete.cases(.)) %>%
    mutate(alpha = alpha/max(alpha),
           strain = strain/max(strain)) %>%
  gather(., key = type, value = value, alpha:strain) %>%
  ggplot(., aes(y = value, x = NodesAttacked)) + 
  geom_point(aes(colour = as.factor(ec), shape = factor(fract))) +
  geom_smooth( se = FALSE, colour = "black", linetype = 2) +
  facet_wrap(~type, labeller = label_parsed) + #parsing shows the plotmath
  labs(title = "Analysing the spread of outcomes for mean loading and relative strain", 
       x = "Fraction of Edges Attacked", y = "metric value",
       colour = "Original\nsystem\ntolerance")  

```

#do the loess
```{r}
#this is loadded seperately to reduce overhead on the large calculations. Really this analysis should be entirely seperate from the rest of the script.
library(yardstick)

loess_alpha <- loess(formula = NodesAttacked~ alpha, 
      data = Permuted_IEEE_118_results)


loess_strain <- loess(formula = NodesAttacked~ strain, 
      data = Permuted_IEEE_118_results)


model_comp <- Permuted_IEEE_118_results %>%
  mutate(alpha_preds = predict(loess_alpha),
         strain_preds = predict(loess_strain))

metrics(Permuted_IEEE_118_results, NodesAttacked, alpha)

metrics(Permuted_IEEE_118_results, NodesAttacked, strain)


metrics(model_comp, NodesAttacked, alpha_preds)

metrics(model_comp, NodesAttacked, strain_preds)

```


#Dummy Chunk
run all the chunks above
```{r}

```


#Strain and quantity

I beleive that strains link to robustness is mediated throught the concentration of demand and generation nodes.
I will test this by doing the following on the largest block of the IEEE 118 network
Using the largest component prevents dead areas of the network and ensures that the all the experiments are topologically identical

5 quantities of generator fraction is used either 17, 12, 8, 4, 1, or a single generator 
20 random samples of each generator level
5 alpha levels 1, 1.5, 2, 5, Inf

This makes 500 different combinations to try + 5 at 100% of all generators

I then 

```{r}

IEEE_118 <- readRDS(file = file.path(IEEE_networks, "IEEE_118_igraph.rds"))

#alpha levels of the concentrator
alpha_conc <- c(1, 1.5, 2, 5, Inf)

List_of_BiConComps <- Create_balanced_blocks(IEEE_118, force = "Net_Generation")

giant_componant <-List_of_BiConComps %>% map_dbl(~vcount(.x)) %>% which.max()

exp_IEEE <- List_of_BiConComps[[giant_componant]]

#In this case the base slack ref will be the largest power consumer
SlackRef_conc <- "59"

#Generate Attack orders
set.seed(21256)
DeleteOrders_Concentrator_Edges <- MultiAttackOrder(exp_IEEE, Target ="Edges", Sims = 100, Name = "Link")  


#get the node id of all the generators
gen_id <- as_data_frame(exp_IEEE, what = "vertices") %>% filter(Generation_MW >0) %>% pull(name) 

#make a df of all combinations of sample size and sample iteration
combs <- expand.grid(x = c(4,8,12), y = 1:20) %>%
  as_tibble 

quant_alpha_comb <- expand.grid(quant = c(17, 12, 8, 4, 1), alpha = alpha_conc) %>%
  as_tibble


active_gen_df <- map2_df(.x  = combs$x, .y = combs$y, ~{
  
  tibble(active_gen_id =  sample(gen_id, .x, replace = FALSE), sample = .y, quant = .x)
  
}) %>%
  bind_rows(tibble(active_gen_id =  gen_id, sample = 1, quant = 17)) %>% #there is only 1 combination of all generators
  bind_rows(tibble(active_gen_id =  gen_id, sample = 1:17, quant = 1)) %>% #there are only 17 for sample size of 1 so this is added on after the others
left_join(quant_alpha_comb,., by = "quant" ) #join so that each specific quant-sample combo is represented at each alpha quant

#the unique simulation combos to be calculated
simulation <-active_gen_df %>% 
  select(-active_gen_id) %>%
  distinct()

cpu_id <- 4
number_of_cpus <- 4
cpu_vector <- rep(1:number_of_cpus, length.out = nrow(simulation))
cpu_sims <-(1:nrow(simulation))[cpu_vector==cpu_id]


cpu_sims %>% walk(~{
  #set the simulation to calculate
  current_sim <- simulation %>%
    slice(.x)
  
  #folder name is 
  folder <- file.path(Project_folder, 
                      "Concentrator",
                      paste0("Concentrator_quant_",
                             current_sim$quant, 
                             "_alpha_", 
                             current_sim$alpha, 
                             "_sample_", 
                             current_sim$sample) )
  #create folder if it doesn't already exist
  if(!file.exists(folder)){
    dir.create(folder)
  }
  
  #active gen id's for that simulation
  active_gen_id <-active_gen_df %>%
    filter(sample == current_sim$sample, quant == current_sim$quant, alpha == current_sim$alpha) %>%
    pull(active_gen_id)
  
  #set active generators
  current_gen <- as_data_frame(exp_IEEE, what = "vertices") %>%
    mutate(Generation_MW = if_else(name %in% active_gen_id, Generation_MW, 0),
           Perc_Gen = Generation_MW/sum(Generation_MW), #find the percentage of total gen for each generator
           Generation_MW = Perc_Gen*sum(Load_MW), #scale generation to match the demand
           Net_Generation = Generation_MW-Load_MW) #reset the net generation column
  
  #set alpha level
  current_g <-as_data_frame(exp_IEEE) %>%
    graph_from_data_frame(., directed = FALSE, vertices = current_gen) %>%
    PowerFlow(., SlackRef_conc, Net_generation = "Net_Generation") %>%
    Proportional_Load(., alpha = 1)
  
  
  #try to speed up simulation by setting not using cascade mode when alpha is Inf
  CascadeMode <- ifelse(is.finite(current_sim$alpha), TRUE, FALSE)
  
  #attack grid
  
  SaveMultiAttacks(current_g, 
                   DeleteOrders_Concentrator_Edges, 
                   folder, 
                   TotalAttackRounds = 1000, 
                   CascadeMode = CascadeMode,
                   Demand = "Load_MW",
                   Generation = "Generation_MW",
                   EdgeName = "Link", 
                   VertexName = "name", 
                   Net_generation = "Net_Generation",
                   Target = "Edges")
  
})
  
```


#extract the data
```{r}


ExtractAttackStats(RootFolder = file.path(Project_folder, "Concentrator"), 
                   NewfolderPath = file.path(Project_folder, "Concentrator_Summary"), 
                   Generation = "Net_Generation",
                   EdgeName = "Link",
                   PowerFlow = "PowerFlow",
                   Link.Limit = "Link.Limit")



#Load the saved files
AttackRoundData <- list.files(path =file.path(Project_folder, "Concentrator_Summary"), 
                              pattern = ".rds", 
                              full.names = TRUE)  %>%
   map_df(~read_rds(.x)) 


test <- AttackRoundData %>%
  arrange(-TotalNodes) %>%
  mutate(has_gc = mean_degree_sqrd > 2*mean_degree) %>%
  filter(!has_gc) %>% 
  group_by(simulationID, alpha) %>%
  summarise_all(first) %>%
  separate(alpha, c("drop1", "drop2","quant","drop3", "alpha_value", "drop4", "sample"), sep = "_") %>%
  mutate(quant = as.integer(quant),
         alpha_value = as.numeric(alpha_value),
         totals = n()) %>%
  select(-contains("drop")) %>%
  group_by(quant, alpha_value) %>%
  summarise_all(mean)

```


#Strain
This looks at how strain functions as a robustness metric

```{r}

Calc_line_strain <- function(g, solved_height_df, distance){
  
  line_strain <-as_data_frame(g) %>% as_tibble %>%
  left_join(., solved_height_df %>% select(node, z), by = c("from"= "node")) %>%
  left_join(., solved_height_df %>% select(node, z), by = c("to"= "node")) %>%
  mutate(dz = abs(z.x-z.y),
         mean_z = (z.x+z.y)/2,
         H = sqrt(dz^2 +{{distance}}^2),
         strain = (H-{{distance}})/{{distance}},
         alpha = Link.Limit/abs(PowerFlow),
         line_load = abs(PowerFlow)/Link.Limit,
         percentile_strain = percent_rank(strain)) %>%
  select(Link, alpha, line_load, dz, H, strain, percentile_strain, mean_z, PowerFlow)
  
}


test <- list.files("/media/jonno/Seagate Expansion Drive/IEEE_Networks/Solved_height_networks", full.names = T) %>%
  map_df(~{
    
    alpha <- basename(.x) %>% gsub("IEEE_118_alpha_", "", .) %>% gsub(".rds", "", .) %>% as.numeric()

    IEEE_118_test<- Proportional_Load(IEEE_118, alpha = alpha) %>%
      set.edge.attribute(. , "distance", value = 1)
    
    read_rds(.x) %>%
      Calc_line_strain(IEEE_118_test , ., distance = distance)

    
  })




test %>%
  ggplot(aes(x = strain, colour = as.factor(alpha))) + geom_density()

test_strain <- test %>%
  mutate(alpha = round(alpha, 5)) %>%
  group_by(alpha) %>%
  summarise(mean = mean(strain),
            median = median(strain),
            weighted.mean = weighted.mean(strain, abs(PowerFlow)),
            counts = n())

test_strain %>%
  ggplot()

test_strain %>%
  gather(key = type, value = strain, -alpha, -counts) %>%
  ggplot(aes(x = 1/alpha, y = strain, colour = type )) + geom_point()

```


#explore convergence

It seems that the algorithm is not converging properly.
I am getting large difference between the infinite model and the a = 10 random ex model.
This below chunk tries to test if 16k and t = 0.3 is good enough, or just what is going on

The algorithm is converging properly. The vairability in the number of nodes needed for complete collapse is so high for low values of alpha that even 100 simualtion has a few dodgy values
```{r}

#calculate theta for all values of alpha
finnesse_prop <-c(1.1, 1.05) %>% map_df(~{
  
  alpha <- .x
  
  print(paste("alpha value", alpha))
  
  current_graph  <- IEEE_118 %>%
    Proportional_Load(., alpha = alpha) %>% 
    set.edge.attribute(. , "distance", value = 1) %>%
    Calc_Spring_Youngs_Modulus(., "PowerFlow", "Link.Limit", 100, 10) %>%
    set.edge.attribute(., "Area", value = 1)
  
  List_of_BiConComps <- Create_balanced_blocks(current_graph, force = "Net_Generation")
  
  #use the largest block to set the simulation parameters k and m.
  #k needs to be sufficiently stretch to allow enough topology variation. otherwise all that happens is a surface angled in the direct of net power flow. Which is interesting but not that interesting
  OriginBlock <- Find_network_balance(List_of_BiConComps[[11]], force = "Net_Generation", 
                                      tstep = 0.01, tol = common_tol, distance = "distance", 
                                      maxIter = 75000, mass = common_mass)
  
  final_z <- Create_stabilised_blocks(current_graph, OriginBlock, 11, force = "Net_Generation", 
                                      tstep = 0.01, tol = common_tol, distance = "distance", 
                                      maxIter = 75000, mass = common_mass) %>%
    mutate(ec = .x)
  
return(final_z)
})


test <-c(1.05, 1.1) %>% map_df(~{
  
test_g <- IEEE_118  %>%
    Proportional_Load(., alpha = .x) %>% 
    set.edge.attribute(. , "distance", value = 1) %>%
    Calc_Spring_Youngs_Modulus(., "PowerFlow", "Link.Limit", 100, 10)
  
  finnesse_prop %>%
    filter(ec == .x) %>%
  Calc_line_strain(test_g, ., distance) 
}) %>%
  mutate(alpha = round(alpha, 5)) %>%
  group_by(alpha) %>%
  summarise(strain = mean(strain))

test2 <- theta_crit_thresh %>%
  mutate(alpha = 1/alpha) %>%
  select(alpha,  NodesAttacked, theta_degs, orig_strain)

```


